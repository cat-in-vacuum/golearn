package theory

// ------------------------------
//           Планировщики
// ------------------------------

//  Планировщик ОС
// ------------------------------
// Программа - просто набор инструкций, которые выполняются (последовательно) одна за другой  (путь исполнения).
// Для исполнения инструкций ОС использует концепцию потока. Выполнение потока будет происходить
// до тех пор, пока инструкции не закончатся.

// Каждая запущенная программа создает процесс, а к каждому процессу - начальный поток. Каждый поток может
// создавать больше потоков, все потоки могут работать независимо друг от друга и решения по планированию
// принимаются на уровне потоков, а не на уровне процессов.

// Потоки могут работать одновременно - каждый по очереди на отдельном ядре, либо параллельно - каждый работает
// одновременно на разных ядрах. Потоки поддерживают свое состояние, чтобы обеспечить безопасное локальное и
// независимое выполнение инструкций.

// Планировщик ОС отвечает за то, что бы ядра не простаивали, если есть потоки, которые могут выполняться.
// Планировщик создает иллюзию, что все потоки выполняются одновременно.
// Планировщик запускает потоки согласно приоритету потока. + планировщик старается сократить
// задержки при планировании принимая решения.

// Выполнение инструкций
// Счетчик команд, также (instruction pointer) (IP) позволяет потоку отслеживать следующую команду
// для выполнения. В большинстве процессоров IP указывает на следующую инструкцию, а не на текущую

// Состояние потока
// Всего три состояния:
//  - ожидание           - поток ждет чего либо для продолжения (диск, сеть, сис вызовы, мьютексы, атомарные).
//                         все эти вызовы основная причина плохой производительности.

//  - готовность         - поток требует времени выполнения на ядре. Т.е. он уже готов выполнять инструкции
//                         и просит времени у проца. Больше потоков - каждый дольше ждет,
//                         очереди для времени выполнения
//                         + сокращается получаемое время, т.к. каждый поток конкурирует за него.
//  - выполнение         - поток размещен на ядре и выполняет инструкции.

// поток может выполнять два типа работ:
// - CPU-Bound это работа, которая никога не создает ситуацию когда поток переводится в режим ожидания.
//      т.е. всегда происходят расчеты
// - IO-Bound это работа, которая заставляет потоки переходить в режим ожидания. Запросы доступа к ресурсам сети
//       или системные вызовы в операционной системе. Мьютексы и атомарные типы также заставляют поток ждать.

// Переключение контекста
// Linux, Mac, Windows работают с вытесняющим планировщиком
// т.е. решение о переключении процессора с одного потока выполнения на другой  принимаются на уровне ОС
// при НЕВЫТЕСНЯЮЩЕЙ многозадачности планировщик непредсказуем. Т.е. мы не можем сказать, что какие
// будут выполняться в данный момент времени. Приоритеты потоков выполнения вместе с событиями( например, получение
// данных в сети) делают невозможным определение того, что будет выбранно планировщиком в данный момент времени.
// ткаже не стоит писать код, который основан на некотором предполагаемом поведении. Нужно контролировать
// синхронизацию и оркестровку потоков, если нужно иметь детерминированное поведенеие в приложении.

// ПЕРЕКЛЮЧЕНИЕ КОНТЕКСТА это процесс прекращения работы потока с сохраненим состояния нужного для
//   восстановления его работы.
//  Т.е. поток из очереди выполнение переходит в состояние выполенения, а выполнявшийся переходит в очередь ожидания
// в состояние ожидания.
// ВЫВОД таков что для io-bound работы панацея это переключение контекста, но для cpu-bound это
// сильно скажется на производительности.

// Одна из  проблем планирования это сколько выдать времени каждому потоку на работу.
// например, если потоков сильно много, то каждый из них может получить меньше времени на работу, чем занимает
// само переключение контекста. По этому планировщику так-же приходится решать, как ограничить минимальное время
// которое будет выделенно каждому потоку на выполенение.

// Есть правило - "МЕНЬШЕ - БОЛЬШЕ".
// Чем меньше потоков в состоянии готовности, тем больше процессорного времени получит каждый из них на работу.

// КЕШ ПРОЦЕССОРА
// кеш процессора используется что бы держать данные как можно ближе к аппаратным потокам, которые в них нуждаются
// доступ к данным из кеша обходится от 10 до 100 раз дешевле.
// Обмен данными между процом и основной памятью осуществляется при помощи строк кеша.
// Строка кеша - 64 байт фрагмент памяти, который обменивается между основной памятью и системой кеша.
// каждое ядро проса получает свою собственную копию любой сторки кеша.
// когда один поток вносит изменения в строку кеша, другие копии этой строки на аппаратном уровне должны быть
// помечены как грязные. Когда поток пытается получить доступ к грязной строке, в таком случае нужно получить
// доступ к основной памяти для получения новой строки кеша.
// На 2 ядреном проце это может бтыь не проблемной, но что делать, если ядра 32. А если два процессора по 16 ядер?
// Эта проблема называется КОГЕРЕНТНОСТЬ КЕША.
// Это все стоит учитывать при написании приложений, которые имею состояние.


// -------- Панировщик ГО
// Когда запускается ГО программа ей присваивается логический процессор(P) для каждого виртуального ядра, которое
// определенно на хост машине. (если аппаратные потоки-то тоже вирт. ядро)
// Например, есть 4 ядра (по два потока на каждое), тогда программа получит 8(P).
// Для каждого P будет назначен поток ОС(M).
// M управляется из ОС, ОС отвечает за размещение M на P
// Горутину можно представлять как поток уровня приложения.

// в лпанировщике есть две очереди на выполнение:
 - GRQ      для горутин, которые не были назначенны для P
 - LRQ      приставивается каждому P, управляет горутинами назначенными в контексте P.
	        Эти горутины по очереди включаются и выключаются из M, назначенного для P

// приложения, которые работают поверх ОС не контроллируют планирование внутри
// ядра(кроме атомарных операций, мьютексов)
Планировщик го - кооперативным, а не вытяесняющий. (с го 1.14 есть нюансы, при гомакс проц =1, если
 загрузить ядро бесконечныйм циклом в отдельной горутине и
если явно не указать runtime.Gosheed() то основная горутина не сможет продолжить работу)

У горутин есть три состояния:
	 ожидание (на сисколах, синхронизациях)
     готовность (горутина хочет получить время). Если горутин много - дольше горутине ждать, что бы поработать
     выполнение

Переключение контекста.
	планировщик го ждет четкие действия для переключения контекста, которые происходят в безопасных точках кода.
	Эти действия(события) позовляют планировщику принять решения о планировнии (не гарантируют, а дают возможность)

    - использование слова go.              При создании новой горутины планирощик получает возможность
    ---------------------                  принять решение о планировании

    - сборщик мусора                       У GC свой набор горутин. Планировщик может переключить выполнение на
    --------------------                   горутину которая хочет сделать сискол вовремя сборки мусора. Во время
                                           работы GC принимается много решений по планированию.

    - сисколы                              Если горутина делает сискол, который заставит блокировать М, планировщик
    --------------------                   может переключить контекст на другую горутину

    - синхронизация                        если вызовы синхронизации блокируют работу горутины, планировщик может
                                           переключить контекст для запуска новой горутины. Как только горутина может
                                           работать снова, она может быть поставлена в очередь и в
                                           конечном итоге переключиться обратно на M
Асинхронные системные вызовы
network poller - обработка сетевых операций.
	используя network poller планировщик может запретить горутинам блокировать М при выполнении системных вызовов
    Это помогает держать М доступным для выполнения других горутин в LRQ Р не создавая новые М.
	Пример: г1 работает на М. В момент когда ей нужно выполнить сискол она перескаивает на нетворк пуллер, в это
    время на М переходит другая горутина из LRQ.
	Когда г1 осуществила сискол она может быть возвращенна в LRQ для Р.
	у network poller есть свой поток ОС и в этом преимущество и он работает через event loop.

Синхронные системные вызовы.
(пример файловый ввод/вывод)
 При синхронном вызове планировкщик может отделить горутину г1 и М1 от Р, выделить новый М(М2) для Р.
	В момент окончания синхронного сискола планировщик отодвинет м1 в строну для будущих использований, а г1
    вернется в LRQ. При повторой ситуации переход произойдет быстрее, т.к. м1 уже будет готов к "обмену".

	Work sltealing
Если у P закончились горутины в LRQ он проверит, есть ли у Р2 горутины его LRQ. Если есть, то заберет половину.
	Если нет, то проверит GRQ и распедалит горутины оттуда. Т.е. М, по сути, всегда занята и не простаивает.